import os
import pickle
from time import time
import json

import numpy.random
import tensorflow as tf
from supervised.data_structures import ModelData


class Config:
    hardware_params = None
    network_params = None
    dataset_params = None
    experiment_params = None

    def __init__(self, hardware_params=None, network_params=None, dataset_params=None, experiment_params=None):
        self.hardware_params = hardware_params
        self.network_params = network_params
        self.dataset_params = dataset_params
        self.experiment_params = experiment_params

    def dump(self, fp):
        pickle.dump(self, fp)

    def load(self, fp):
        obj = pickle.load(fp)
        self.hardware_params = obj.hardware_params
        self.network_params = obj.network_params
        self.dataset_params = obj.dataset_params
        self.experiment_params = obj.experiment_params


def prep_gpu(cpus_per_task, gpus_per_task=0):
    """prepare the GPU for tensorflow computation"""
    # tell tensorflow to be quiet
    # os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
    # Turn off GPU?
    if not gpus_per_task:
        os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

    # TODO: use pynvml here to select an appropriate gpu
    physical_devices = tf.config.get_visible_devices('GPU')
    n_physical_devices = len(physical_devices)
    print(physical_devices)

    # use the available cpus to set the parallelism level
    if cpus_per_task is not None:
        tf.config.threading.set_inter_op_parallelism_threads(cpus_per_task)
        tf.config.threading.set_intra_op_parallelism_threads(cpus_per_task)

    if n_physical_devices > 1:
        for physical_device in physical_devices:
            tf.config.experimental.set_memory_growth(physical_device, True)
        print('We have %d GPUs\n' % n_physical_devices)
    elif n_physical_devices:
        print('We have %d GPUs\n' % n_physical_devices)
    else:
        print('NO GPU')


def generate_fname(args):
    # TODO: fix this
    """
    Generate the base file name for output files/directories.

    The approach is to encode the key experimental parameters in the file name.  This
    way, they are unique and easy to identify after the fact.

    :param args: from argParse
    :params_str: String generated by the JobIterator
    :return: a string (file name prefix)
    """
    return f"{str(time()).replace('.', '')[-6:]}"


def execute_exp(model, train_dset, val_dset, network_params, experiment_params,
                train_steps=None, val_steps=None, callbacks=None, evaluate_on=None):
    """
    Perform the training and evaluation for a single model

    :param args: Argparse arguments object
    :param model: keras model
    :param train_dset: training dataset instance
    :param val_dset: validation dataset instance
    :param train_iteration: training iteration
    :param train_steps: number of training steps to perform per epoch
    :param val_steps: number of validation steps to perform per epoch
    :param callbacks: callbacks for model.fit
    :param evaluate_on: a dictionary of objects on which to call model.evaluate (take care they are not infinite)
    :return: trained keras model encoded as a ModelData instance
    """

    print(model.summary())
    # tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True,
    #                          to_file=os.curdir + f'/../visualizations/models/model_{str(time())[:6]}.png')
    # Perform the experiment?
    if experiment_params['nogo']:
        # No!
        print("NO GO")
        return

    # Learn
    #  steps_per_epoch: how many batches from the training set do we use for training in one epoch?
    #  validation_steps=None
    #  means that ALL validation samples will be used (of the selected subset)
    print(val_steps)
    history = model.fit(train_dset,
                        epochs=experiment_params['epochs'],
                        verbose=True,
                        validation_data=val_dset,
                        validation_steps=val_steps,
                        callbacks=callbacks,
                        steps_per_epoch=train_steps,
                        shuffle=False)

    evaluate_on = dict() if evaluate_on is None else evaluate_on

    evaluations = {k: model.evaluate(evaluate_on[k], steps=val_steps) for k in evaluate_on}

    # populate results data structure
    model_data = ModelData(weights=model.get_weights(),
                           network_params=network_params,
                           network_fn=network_params['network_fn'],
                           evaluations=evaluations,
                           classes=network_params['network_args']['n_classes'],
                           history=history.history)
    print('returning model data')
    return model_data


def start_training(model,
                   train_dset,
                   val_dset,
                   network_params,
                   experiment_params,
                   evaluate_on=None,
                   train_steps=None,
                   val_steps=None):
    """
    train a keras model on a dataset and evaluate it on other datasets then return the ModelData instance

    :param model: keras model
    :param train_dset: tf.data.Dataset for training
    :param val_dset: tf.data.Dataset for evaluation
    :param evaluate_on: a dictionary of finite objects passable to model.evaluate
    :param train_steps: number of steps per epoch
    :param val_steps: number of validations steps per epoch
    :return: a ModelData instance
    """
    # Override arguments if we are using exp_index

    train_steps = train_steps if train_steps is not None else 100
    val_steps = val_steps if val_steps is not None else 100

    print(train_steps, val_steps)

    evaluate_on = dict() if evaluate_on is None else evaluate_on

    def bleed_out(index, lrate=1e-3, minimum=1e-3):
        # Oscillating learning rate schedule
        # inspired by https://arxiv.org/abs/1506.01186
        from math import sin, pi
        x = index + 1
        frac = (1 - minimum) / x ** (1 - sin(2 * pi * (x ** .5)))
        return min(network_params['network_args']['lrate'] * (frac + minimum), 1)

    def cyclical_adv_lrscheduler25(epoch, lrate):
        """CAI Cyclical and Advanced Learning Rate Scheduler.
        # Arguments
            epoch: integer with current epoch count.
        # Returns
            float with desired learning rate.
        """
        base_learning = 0.001
        local_epoch = epoch % 25
        if local_epoch < 7:
            return base_learning * (1 + 0.5 * local_epoch)
        else:
            return (base_learning * 4) * (0.85 ** (local_epoch - 7))

    callbacks = [tf.keras.callbacks.EarlyStopping(patience=experiment_params['patience'],
                                                  restore_best_weights=True,
                                                  min_delta=experiment_params['min_delta'],
                                                  monitor='val_categorical_accuracy'),
                 tf.keras.callbacks.LearningRateScheduler(bleed_out)]

    return execute_exp(model, train_dset, val_dset, network_params, experiment_params,
                       train_steps, val_steps, callbacks=callbacks, evaluate_on=evaluate_on)


class Experiment:
    """
        The Experiment class is used to run and enqueue deep learning jobs with a config dict
    """

    def __init__(self, config):
        self.batch_file = None
        self.network_params = config.network_params
        self.hardware_params = config.hardware_params
        self.dataset_params = config.dataset_params
        self.params = config.experiment_params

    def run(self):
        # TODO: run locally
        """
        1. prep the hardware (prep_gpu)
        2. get the data
        3. make the model
        4. fit the model
        5. save the data
        """
        # set seed
        tf.random.set_seed(self.params['seed'])
        numpy.random.seed(self.params['seed'])

        prep_gpu(self.hardware_params['n_cpu'], self.hardware_params['n_gpu'])

        network_fn = self.network_params['network_fn']
        network_args = self.network_params['network_args']

        if self.hardware_params['distributed']:
            # create the scope
            strategy = tf.distribute.MirroredStrategy()
            with strategy.scope():
                # build the model (in the scope)
                model = network_fn(**network_args)
        else:
            model = network_fn(**network_args)

        dset_dict = self.dataset_params['dset_fn'](**self.dataset_params['dset_args'])

        train_dset, val_dset, test_dset = dset_dict['train'], dset_dict['val'], dset_dict['test']

        def postprocess_dset(ds):
            if self.dataset_params['batch'] > 1:
                ds = ds.batch(self.dataset_params['batch'])

            if self.dataset_params['cache']:
                if isinstance(self.dataset_params['cache'], str):
                    ds = ds.cache(self.dataset_params['cache'])
                else:
                    ds = ds.cache()

            if self.dataset_params['shuffle']:
                ds = ds.shuffle(self.dataset_params['shuffle'], self.params['seed'], True)

            ds = ds.repeat()

            ds = ds.prefetch(self.dataset_params['prefetch'])

            return ds

        val_dset = val_dset.batch(self.dataset_params['batch']).repeat()

        train_dset = postprocess_dset(train_dset)

        for aug in self.dataset_params['augs']:
            train_dset = aug(train_dset)
        # train the model
        if self.network_params['hyperband']:
            return start_training(model, train_dset, val_dset, self.network_params, self.params,
                                  train_steps=self.params['steps_per_epoch'],
                                  val_steps=self.params['validation_steps'],
                                  evaluate_on={'test': test_dset})

        model_data = start_training(model, train_dset, val_dset, self.network_params, self.params,
                                    train_steps=self.params['steps_per_epoch'],
                                    val_steps=self.params['validation_steps'])

        with open(f'{os.curdir}/../results/{generate_fname(self.params)}', 'wb') as fp:
            pickle.dump(model_data, fp)

    def run_array(self, index=0):
        # TODO: job iterator and search space code for multiple jobs
        # TODO: pick job by index
        pass

    def enqueue(self):
        # TODO: queue a slurm job
        """
        1. save the current Experiment object to a pickle temp file
        2. create the batch file /  hardware params
        3. sbatch the batch file
        """
        pass


class Results:
    """
        The Results class is used to display results for an experiment from a file path
    """

    # TODO
    def __init__(self):
        pass
